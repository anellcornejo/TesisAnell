{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv1D , Dropout , Flatten , MaxPooling1D, Dense, Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model , load_model\n",
    "import random\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga y distribución de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anell/anaconda3/envs/python37-astronn/lib/python3.7/site-packages/ipykernel_launcher.py:3: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos\n",
    "path_local_data = '/home/anell/Desktop/Bovy/AnellExercises/Fits_files'\n",
    "with h5py.File(f'{path_local_data}/apogeedr14_gaiadr2_with_spectrum_probando_rendimiento_1.h5') as F:  \n",
    "    parallax = np.array(F['parallax'])\n",
    "    parallax_error = np.array(F['parallax_err'])\n",
    "    spectra = np.array(F['spectra'])\n",
    "    Kmag = np.array(F['corrected_magnitude_K'])\n",
    "    bp_rp = np.array(F['bp_rp'])\n",
    "    Gmag = np.array(F['phot_g_mean_mag'])\n",
    "    teff = np.array(F['NN_teff'])\n",
    "    apogee_id = np.array(F['APOGEE_ID'])\n",
    "    snr = np.array(F['SNR'])\n",
    "    fe_h = np.array(F['Fe/H'])\n",
    "    path_spectra = np.array(F['Path_spectra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57696,), (57696, 7514), (57696,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallax.shape , spectra.shape , Kmag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_snr =[]\n",
    "for i in range(len(snr)):\n",
    "    if snr[i] > 20:\n",
    "        cut_snr.append(i)\n",
    "        \n",
    "parallax = parallax[cut_snr]\n",
    "parallax_error = parallax_error[cut_snr]\n",
    "spectra = spectra[cut_snr]\n",
    "Kmag = Kmag[cut_snr]\n",
    "bp_rp = bp_rp[cut_snr]\n",
    "Gmag = Gmag[cut_snr]\n",
    "teff = teff[cut_snr]\n",
    "apogee_id = apogee_id[cut_snr]\n",
    "snr = snr[cut_snr]\n",
    "fe_h = fe_h[cut_snr]\n",
    "path_spectra = path_spectra[cut_snr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57565,), (57565, 7514), (57565,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallax.shape, spectra.shape, Kmag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos Gmag , el color (G_bp - G_rp) y teff\n",
    "Gmag_std = np.std(Gmag)\n",
    "Gmag_mean = np.mean(Gmag)\n",
    "Gmag_norm = (Gmag - Gmag_mean) / Gmag_std\n",
    "\n",
    "bp_rp_std = np.std(bp_rp)\n",
    "bp_rp_mean = np.mean(bp_rp)\n",
    "bp_rp_norm = (bp_rp - bp_rp_mean) / bp_rp_std\n",
    "\n",
    "teff_std = np.std(teff)\n",
    "teff_mean = np.mean(teff)\n",
    "teff_norm = (teff - teff_mean) / teff_std\n",
    "\n",
    "\n",
    "#EStablecemos las variables que entrarán a la red y corregimos sus dimensiones\n",
    "X = np.expand_dims(spectra,axis = 2)\n",
    "Y = np.expand_dims(parallax,axis=1)\n",
    "Y_error = np.expand_dims(parallax_error,axis=1)\n",
    "K_mag = np.expand_dims(Kmag,axis=1)\n",
    "G_mag = np.expand_dims(Gmag_norm,axis=1)\n",
    "Bp_Rp = np.expand_dims(bp_rp_norm,axis=1)\n",
    "Teff = np.expand_dims(teff_norm,axis=1)\n",
    "Snr = np.expand_dims(snr,axis=1)\n",
    "FeH = np.expand_dims(fe_h,axis=1)\n",
    "Teff_without_norm = np.expand_dims(teff,axis=1)\n",
    "\n",
    "X_offset = np.concatenate((G_mag, Bp_Rp , Teff), axis = 1) \n",
    "\n",
    "#Aleatorizamos la muestra\n",
    "idx = []\n",
    "for i in range(len(X)):\n",
    "    idx.append(i)\n",
    "random.seed(20)\n",
    "random.shuffle(idx)\n",
    "    \n",
    "X = X[idx]                                       # shape: (15644, 7514 , 1)   \n",
    "Y = Y[idx]                                       # shape: (15644, 1)  \n",
    "K_mag = K_mag[idx]                               # shape: (15644, 1) \n",
    "X_offset = X_offset[idx]                         # shape: (15644, 3)\n",
    "SNR = Snr[idx]                                   # shape: (15644, 1)\n",
    "FeH = FeH[idx]                                   # shape: (15644, 1)\n",
    "Teff_without_norm = Teff_without_norm[idx]       # shape: (15644, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57565, 7514, 1), (57565, 1), (57565,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape , Y.shape, parallax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definición del modelo\n",
    "def ApogeeDR14GaiaDR2(dim_t , dim_n): \n",
    "    \"\"\"\n",
    "    INPUT: \n",
    "    dim_t - number of time steps of spectrum \n",
    "    dim_n - number of features of spectrum\n",
    "    \"\"\"\n",
    "    \n",
    "    #SPECTRUM TO LUINOSITY\n",
    "    dim_1 = 1 # number of corrected magnitude for one example \n",
    "    units = 1 #number of final output for one example\n",
    "    inputs_spectra = Input(shape=(dim_t, dim_n)) \n",
    "    inputs_mag = Input(shape=(dim_1,), name=\"ApparentMagnitude-input\")\n",
    "    \n",
    "    x_parallax = Conv1D(filters=4, kernel_size=2, activation='relu')(inputs_spectra)\n",
    "    x_parallax = MaxPooling1D(pool_size=2)(x_parallax)\n",
    "    x_parallax = Flatten()(x_parallax)\n",
    "    x_parallax = Dense(164, activation='relu')(x_parallax) #relu\n",
    "    x_parallax = Dense(164, activation='tanh')(x_parallax) #tanh\n",
    "    x_parallax = Dense(64, activation='relu')(x_parallax) \n",
    "    x_parallax = Dense(64, activation='tanh')(x_parallax)\n",
    "    x_parallax = Dense(32, activation='relu')(x_parallax)\n",
    "    x_parallax = Dense(units, activation='softplus')(x_parallax)\n",
    "    \n",
    "    outputs_parallax = Lambda(lambda function: tf.math.multiply(function[0], tf.math.pow(10., \n",
    "                              tf.math.multiply(-0.2, function[1]))),\n",
    "                              name='luminosity-to-parallax')([x_parallax, inputs_mag])\n",
    "   \n",
    "    #OFFSET CORRECTION : (optimization)\n",
    "    inputs_offset = Input(shape=(3,), name=\"Offset-input\")\n",
    "    x_offset = Dense(64, activation='relu')(inputs_offset)\n",
    "    x_offset = Dense(32, activation='relu')(x_offset) \n",
    "    x_offset = Dense(units, activation='tanh')(x_offset) \n",
    "    \n",
    "    outputs_parallax_with_offset = Lambda(lambda function: tf.math.add(function[0], function[1]),\n",
    "                                          name=\"Sum-parallax-offset\")([outputs_parallax, x_offset]) \n",
    "    \n",
    "    #Model setup\n",
    "    model =  Model(inputs = [inputs_spectra,inputs_mag, inputs_offset],outputs = [outputs_parallax_with_offset])\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formación del set de entrenamiento\n",
    "good_idx_snr = []\n",
    "bad_idx_snr = []\n",
    "for i in range(len(SNR)):\n",
    "    if SNR[i] >= 200:           \n",
    "        good_idx_snr.append(i)\n",
    "    else:\n",
    "        bad_idx_snr.append(i)\n",
    "\n",
    "#SET ENTRENAMIENTO\n",
    "X_train_snr = np.concatenate((X[good_idx_snr][:4000],X[bad_idx_snr][:2000]),axis = 0)\n",
    "Y_train_snr = np.concatenate((Y[good_idx_snr][:4000],Y[bad_idx_snr][:2000]),axis = 0)\n",
    "K_mag_train_snr = np.concatenate((K_mag[good_idx_snr][:4000],K_mag[bad_idx_snr][:2000]),axis = 0)\n",
    "X_offset_train_snr = np.concatenate((X_offset[good_idx_snr][:4000],X_offset[bad_idx_snr][:2000]),axis = 0)\n",
    "\n",
    "idx_random = []\n",
    "for i in range(len(X_train_snr)):\n",
    "    idx_random.append(i)\n",
    "random.seed(1000)\n",
    "random.shuffle(idx_random)\n",
    "\n",
    "X_train_snr = X_train_snr[idx_random]\n",
    "Y_train_snr = Y_train_snr[idx_random]\n",
    "K_mag_train_snr = K_mag_train_snr[idx_random]\n",
    "X_offset_train_snr = X_offset_train_snr[idx_random]\n",
    "\n",
    "#SET DE VALIDACIÓN\n",
    "#X_val_snr = np.concatenate((X[good_idx_snr][4000:5500],X[bad_idx_snr][2000:2500]),axis = 0)\n",
    "#Y_val_snr = np.concatenate((Y[good_idx_snr][4000:5500],Y[bad_idx_snr][2000:2500]),axis = 0)\n",
    "#K_mag_val_snr = np.concatenate((K_mag[good_idx_snr][4000:5500],K_mag[bad_idx_snr][2000:2500]),axis = 0)\n",
    "#X_offset_val_snr = np.concatenate((X_offset[good_idx_snr][4000:5500],X_offset[bad_idx_snr][2000:2500]),axis = 0)\n",
    "\n",
    "#idx_random_val = []\n",
    "#for i in range(len(X_val_snr)):\n",
    "#    idx_random_val.append(i)\n",
    "#random.seed(5000)\n",
    "#random.shuffle(idx_random_val)\n",
    "\n",
    "#X_val_snr = X_val_snr[idx_random_val]\n",
    "#Y_val_snr = Y_val_snr[idx_random_val]\n",
    "#K_mag_val_snr = K_mag_val_snr[idx_random_val]\n",
    "#X_offset_val_snr = X_offset_val_snr[idx_random_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 7514, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 7513, 4)      12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 3756, 4)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 15024)        0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 164)          2464100     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 164)          27060       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           10560       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           4160        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Offset-input (InputLayer)       [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           256         Offset-input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            33          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ApparentMagnitude-input (InputL [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           2080        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "luminosity-to-parallax (Lambda) (None, 1)            0           dense_5[0][0]                    \n",
      "                                                                 ApparentMagnitude-input[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            33          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Sum-parallax-offset (Lambda)    (None, 1)            0           luminosity-to-parallax[0][0]     \n",
      "                                                                 dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,510,374\n",
      "Trainable params: 2,510,374\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_features = X_train_snr.shape[1], X_train_snr.shape[2]\n",
    "\n",
    "Global_model = ApogeeDR14GaiaDR2(n_timesteps , n_features)\n",
    "\n",
    "Global_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "47/47 [==============================] - 2s 45ms/step - loss: 14.2433 - mse: 14.2433\n",
      "Epoch 2/300\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 12.5736 - mse: 12.5736\n",
      "Epoch 3/300\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 12.1484 - mse: 12.1484\n",
      "Epoch 4/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 11.9231 - mse: 11.9231\n",
      "Epoch 5/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 11.7959 - mse: 11.7959\n",
      "Epoch 6/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 11.5803 - mse: 11.5803\n",
      "Epoch 7/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 11.2329 - mse: 11.2329\n",
      "Epoch 8/300\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 11.0414 - mse: 11.0414\n",
      "Epoch 9/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.9285 - mse: 10.9285\n",
      "Epoch 10/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.8987 - mse: 10.8987\n",
      "Epoch 11/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.8698 - mse: 10.8698\n",
      "Epoch 12/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.8767 - mse: 10.8767\n",
      "Epoch 13/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.8782 - mse: 10.8782\n",
      "Epoch 14/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.8606 - mse: 10.8606\n",
      "Epoch 15/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.8472 - mse: 10.8472\n",
      "Epoch 16/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.8268 - mse: 10.8268\n",
      "Epoch 17/300\n",
      "47/47 [==============================] - 3s 56ms/step - loss: 10.8438 - mse: 10.8438\n",
      "Epoch 18/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.8206 - mse: 10.8206\n",
      "Epoch 19/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.8259 - mse: 10.8259\n",
      "Epoch 20/300\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 10.8375 - mse: 10.8375\n",
      "Epoch 21/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.8078 - mse: 10.8078\n",
      "Epoch 22/300\n",
      "47/47 [==============================] - 3s 61ms/step - loss: 10.8092 - mse: 10.8092\n",
      "Epoch 23/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.7978 - mse: 10.7978\n",
      "Epoch 24/300\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 10.7969 - mse: 10.7969\n",
      "Epoch 25/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.7928 - mse: 10.7928\n",
      "Epoch 26/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.7842 - mse: 10.7842\n",
      "Epoch 27/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.7767 - mse: 10.7767\n",
      "Epoch 28/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.7783 - mse: 10.7783\n",
      "Epoch 29/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.7715 - mse: 10.7715\n",
      "Epoch 30/300\n",
      "47/47 [==============================] - 3s 56ms/step - loss: 10.7720 - mse: 10.7720\n",
      "Epoch 31/300\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 10.7649 - mse: 10.7649\n",
      "Epoch 32/300\n",
      "47/47 [==============================] - 3s 56ms/step - loss: 10.7754 - mse: 10.7754\n",
      "Epoch 33/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.7526 - mse: 10.7526\n",
      "Epoch 34/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.7554 - mse: 10.7554\n",
      "Epoch 35/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.7477 - mse: 10.7477\n",
      "Epoch 36/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.7459 - mse: 10.7459\n",
      "Epoch 37/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.7400 - mse: 10.7400\n",
      "Epoch 38/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.7304 - mse: 10.7304\n",
      "Epoch 39/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.7382 - mse: 10.7382\n",
      "Epoch 40/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.7454 - mse: 10.7454\n",
      "Epoch 41/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.7172 - mse: 10.7172\n",
      "Epoch 42/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.7119 - mse: 10.7119\n",
      "Epoch 43/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.7182 - mse: 10.7182\n",
      "Epoch 44/300\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 10.6814 - mse: 10.6814\n",
      "Epoch 45/300\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 10.6837 - mse: 10.6837\n",
      "Epoch 46/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.7075 - mse: 10.7075\n",
      "Epoch 47/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.6772 - mse: 10.6772\n",
      "Epoch 48/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.6611 - mse: 10.6611\n",
      "Epoch 49/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.6506 - mse: 10.6506\n",
      "Epoch 50/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.6501 - mse: 10.6501\n",
      "Epoch 51/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.6422 - mse: 10.6422\n",
      "Epoch 52/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.6530 - mse: 10.6530\n",
      "Epoch 53/300\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 10.6380 - mse: 10.6380\n",
      "Epoch 54/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.6175 - mse: 10.6175\n",
      "Epoch 55/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.6300 - mse: 10.6300\n",
      "Epoch 56/300\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 10.6044 - mse: 10.6044\n",
      "Epoch 57/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.6016 - mse: 10.6016\n",
      "Epoch 58/300\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 10.5957 - mse: 10.5957\n",
      "Epoch 59/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.6055 - mse: 10.6055\n",
      "Epoch 60/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5927 - mse: 10.5927\n",
      "Epoch 61/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5968 - mse: 10.5968\n",
      "Epoch 62/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5902 - mse: 10.5902\n",
      "Epoch 63/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5783 - mse: 10.5783\n",
      "Epoch 64/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5687 - mse: 10.5687\n",
      "Epoch 65/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5645 - mse: 10.5645\n",
      "Epoch 66/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5689 - mse: 10.5689: 0s - loss: 10.4358 - mse: 10.435\n",
      "Epoch 67/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.5594 - mse: 10.5594\n",
      "Epoch 68/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.5540 - mse: 10.5540\n",
      "Epoch 69/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.5490 - mse: 10.5490: 1s - loss: \n",
      "Epoch 70/300\n",
      "47/47 [==============================] - 3s 53ms/step - loss: 10.5441 - mse: 10.5441\n",
      "Epoch 71/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5328 - mse: 10.5328\n",
      "Epoch 72/300\n",
      "47/47 [==============================] - 2s 47ms/step - loss: 10.5338 - mse: 10.5338\n",
      "Epoch 73/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.5313 - mse: 10.5313\n",
      "Epoch 74/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5306 - mse: 10.5306\n",
      "Epoch 75/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5421 - mse: 10.5421\n",
      "Epoch 76/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5348 - mse: 10.5348\n",
      "Epoch 77/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5197 - mse: 10.5197\n",
      "Epoch 78/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5275 - mse: 10.5275\n",
      "Epoch 79/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5191 - mse: 10.5191\n",
      "Epoch 80/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5144 - mse: 10.5144\n",
      "Epoch 81/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.5164 - mse: 10.5164\n",
      "Epoch 82/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.5174 - mse: 10.5174\n",
      "Epoch 83/300\n",
      "47/47 [==============================] - 3s 59ms/step - loss: 10.5055 - mse: 10.5055\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 3s 57ms/step - loss: 10.5009 - mse: 10.5009\n",
      "Epoch 85/300\n",
      "47/47 [==============================] - 3s 56ms/step - loss: 10.5107 - mse: 10.5107\n",
      "Epoch 86/300\n",
      "47/47 [==============================] - 3s 56ms/step - loss: 10.5023 - mse: 10.5023\n",
      "Epoch 87/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4963 - mse: 10.4963\n",
      "Epoch 88/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4918 - mse: 10.4918\n",
      "Epoch 89/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.4942 - mse: 10.4942\n",
      "Epoch 90/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.4971 - mse: 10.4971\n",
      "Epoch 91/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4967 - mse: 10.4967\n",
      "Epoch 92/300\n",
      "47/47 [==============================] - 3s 53ms/step - loss: 10.4848 - mse: 10.4848\n",
      "Epoch 93/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.4828 - mse: 10.4828\n",
      "Epoch 94/300\n",
      "47/47 [==============================] - 3s 56ms/step - loss: 10.4850 - mse: 10.4850\n",
      "Epoch 95/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.4834 - mse: 10.4834\n",
      "Epoch 96/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4760 - mse: 10.4760\n",
      "Epoch 97/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4836 - mse: 10.4836\n",
      "Epoch 98/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4984 - mse: 10.4984\n",
      "Epoch 99/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.5071 - mse: 10.5071\n",
      "Epoch 100/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4820 - mse: 10.4820\n",
      "Epoch 101/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4907 - mse: 10.4907\n",
      "Epoch 102/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4858 - mse: 10.4858\n",
      "Epoch 103/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4763 - mse: 10.4763\n",
      "Epoch 104/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4918 - mse: 10.4918\n",
      "Epoch 105/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4827 - mse: 10.4827\n",
      "Epoch 106/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4827 - mse: 10.4827\n",
      "Epoch 107/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4698 - mse: 10.4698\n",
      "Epoch 108/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4776 - mse: 10.4776\n",
      "Epoch 109/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4832 - mse: 10.4832\n",
      "Epoch 110/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4727 - mse: 10.4727\n",
      "Epoch 111/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4686 - mse: 10.4686\n",
      "Epoch 112/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4783 - mse: 10.4783\n",
      "Epoch 113/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4611 - mse: 10.4611\n",
      "Epoch 114/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4576 - mse: 10.4576\n",
      "Epoch 115/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4651 - mse: 10.4651\n",
      "Epoch 116/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4608 - mse: 10.4608\n",
      "Epoch 117/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4579 - mse: 10.4579\n",
      "Epoch 118/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4629 - mse: 10.4629\n",
      "Epoch 119/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4714 - mse: 10.4714\n",
      "Epoch 120/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4649 - mse: 10.4649\n",
      "Epoch 121/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4549 - mse: 10.4549\n",
      "Epoch 122/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4617 - mse: 10.4617\n",
      "Epoch 123/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4740 - mse: 10.4740\n",
      "Epoch 124/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4580 - mse: 10.4580\n",
      "Epoch 125/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4514 - mse: 10.4514\n",
      "Epoch 126/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4511 - mse: 10.4511\n",
      "Epoch 127/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4437 - mse: 10.4437\n",
      "Epoch 128/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4489 - mse: 10.4489\n",
      "Epoch 129/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4682 - mse: 10.4682\n",
      "Epoch 130/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4606 - mse: 10.4606\n",
      "Epoch 131/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4382 - mse: 10.4382\n",
      "Epoch 132/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4404 - mse: 10.4404\n",
      "Epoch 133/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4447 - mse: 10.4447\n",
      "Epoch 134/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4454 - mse: 10.4454\n",
      "Epoch 135/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4404 - mse: 10.4404\n",
      "Epoch 136/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4406 - mse: 10.4406\n",
      "Epoch 137/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4396 - mse: 10.4396\n",
      "Epoch 138/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4484 - mse: 10.4484\n",
      "Epoch 139/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4546 - mse: 10.4546\n",
      "Epoch 140/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4449 - mse: 10.4449\n",
      "Epoch 141/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4457 - mse: 10.4457\n",
      "Epoch 142/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4239 - mse: 10.4239\n",
      "Epoch 143/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4273 - mse: 10.4273\n",
      "Epoch 144/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4469 - mse: 10.4469\n",
      "Epoch 145/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4508 - mse: 10.4508\n",
      "Epoch 146/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4469 - mse: 10.4469\n",
      "Epoch 147/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4351 - mse: 10.4351\n",
      "Epoch 148/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4501 - mse: 10.4501\n",
      "Epoch 149/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4307 - mse: 10.4307\n",
      "Epoch 150/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4364 - mse: 10.4364\n",
      "Epoch 151/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4324 - mse: 10.4324\n",
      "Epoch 152/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4329 - mse: 10.4329\n",
      "Epoch 153/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4255 - mse: 10.4255\n",
      "Epoch 154/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4283 - mse: 10.4283\n",
      "Epoch 155/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4342 - mse: 10.4342\n",
      "Epoch 156/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4246 - mse: 10.4246\n",
      "Epoch 157/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4192 - mse: 10.4192\n",
      "Epoch 158/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4204 - mse: 10.4204\n",
      "Epoch 159/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4138 - mse: 10.4138\n",
      "Epoch 160/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4153 - mse: 10.4153\n",
      "Epoch 161/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4161 - mse: 10.4161\n",
      "Epoch 162/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4243 - mse: 10.4243\n",
      "Epoch 163/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4315 - mse: 10.4315\n",
      "Epoch 164/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4168 - mse: 10.4168\n",
      "Epoch 165/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4322 - mse: 10.4322\n",
      "Epoch 166/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4057 - mse: 10.4057\n",
      "Epoch 167/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 50ms/step - loss: 10.4405 - mse: 10.4405\n",
      "Epoch 168/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.4232 - mse: 10.4232\n",
      "Epoch 169/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.4208 - mse: 10.4208\n",
      "Epoch 170/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.4295 - mse: 10.4295\n",
      "Epoch 171/300\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 10.4216 - mse: 10.4216\n",
      "Epoch 172/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.4092 - mse: 10.4092\n",
      "Epoch 173/300\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 10.4313 - mse: 10.4313\n",
      "Epoch 174/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.4249 - mse: 10.4249\n",
      "Epoch 175/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.4128 - mse: 10.4128\n",
      "Epoch 176/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.4142 - mse: 10.4142\n",
      "Epoch 177/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.4091 - mse: 10.4091\n",
      "Epoch 178/300\n",
      "47/47 [==============================] - 3s 53ms/step - loss: 10.4068 - mse: 10.4068\n",
      "Epoch 179/300\n",
      "47/47 [==============================] - 3s 53ms/step - loss: 10.4041 - mse: 10.4041\n",
      "Epoch 180/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3994 - mse: 10.3994\n",
      "Epoch 181/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.4088 - mse: 10.4088\n",
      "Epoch 182/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4094 - mse: 10.4094\n",
      "Epoch 183/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.4019 - mse: 10.4019\n",
      "Epoch 184/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.4142 - mse: 10.4142\n",
      "Epoch 185/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3966 - mse: 10.3966\n",
      "Epoch 186/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.3919 - mse: 10.3919\n",
      "Epoch 187/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.3897 - mse: 10.3897\n",
      "Epoch 188/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.4466 - mse: 10.4466\n",
      "Epoch 189/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.4231 - mse: 10.4231\n",
      "Epoch 190/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.3945 - mse: 10.3945\n",
      "Epoch 191/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.3904 - mse: 10.3904\n",
      "Epoch 192/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.3952 - mse: 10.3952\n",
      "Epoch 193/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.4098 - mse: 10.4098\n",
      "Epoch 194/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.4071 - mse: 10.4071\n",
      "Epoch 195/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3944 - mse: 10.3944\n",
      "Epoch 196/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3925 - mse: 10.3925\n",
      "Epoch 197/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.3798 - mse: 10.3798\n",
      "Epoch 198/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3991 - mse: 10.3991\n",
      "Epoch 199/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.3888 - mse: 10.3888\n",
      "Epoch 200/300\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 10.3915 - mse: 10.3915\n",
      "Epoch 201/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.3842 - mse: 10.3842\n",
      "Epoch 202/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3912 - mse: 10.3912\n",
      "Epoch 203/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3813 - mse: 10.3813\n",
      "Epoch 204/300\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 10.3923 - mse: 10.3923\n",
      "Epoch 205/300\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 10.3751 - mse: 10.3751\n",
      "Epoch 206/300\n",
      "47/47 [==============================] - 3s 56ms/step - loss: 10.3888 - mse: 10.3888\n",
      "Epoch 207/300\n",
      "47/47 [==============================] - 3s 58ms/step - loss: 10.4112 - mse: 10.4112\n",
      "Epoch 208/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3784 - mse: 10.3784\n",
      "Epoch 209/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3746 - mse: 10.3746\n",
      "Epoch 210/300\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 10.3927 - mse: 10.3927\n",
      "Epoch 211/300\n",
      "47/47 [==============================] - 3s 56ms/step - loss: 10.3851 - mse: 10.3851\n",
      "Epoch 212/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3907 - mse: 10.3907\n",
      "Epoch 213/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3833 - mse: 10.3833\n",
      "Epoch 214/300\n",
      "47/47 [==============================] - 3s 53ms/step - loss: 10.3894 - mse: 10.3894\n",
      "Epoch 215/300\n",
      "47/47 [==============================] - 3s 53ms/step - loss: 10.3772 - mse: 10.3772\n",
      "Epoch 216/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3920 - mse: 10.3920\n",
      "Epoch 217/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3861 - mse: 10.3861\n",
      "Epoch 218/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3736 - mse: 10.3736\n",
      "Epoch 219/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3900 - mse: 10.3900\n",
      "Epoch 220/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3810 - mse: 10.3810\n",
      "Epoch 221/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3857 - mse: 10.3857\n",
      "Epoch 222/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3757 - mse: 10.3757\n",
      "Epoch 223/300\n",
      "47/47 [==============================] - 3s 53ms/step - loss: 10.3766 - mse: 10.3766\n",
      "Epoch 224/300\n",
      "47/47 [==============================] - 3s 53ms/step - loss: 10.3706 - mse: 10.3706\n",
      "Epoch 225/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3616 - mse: 10.3616\n",
      "Epoch 226/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3753 - mse: 10.3753\n",
      "Epoch 227/300\n",
      "47/47 [==============================] - 3s 63ms/step - loss: 10.3761 - mse: 10.3761\n",
      "Epoch 228/300\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 10.3981 - mse: 10.3981\n",
      "Epoch 229/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.4241 - mse: 10.4241\n",
      "Epoch 230/300\n",
      "47/47 [==============================] - 3s 58ms/step - loss: 10.4027 - mse: 10.4027\n",
      "Epoch 231/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.3790 - mse: 10.3790\n",
      "Epoch 232/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.3855 - mse: 10.3855\n",
      "Epoch 233/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.3751 - mse: 10.3751\n",
      "Epoch 234/300\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 10.3793 - mse: 10.3793\n",
      "Epoch 235/300\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 10.3745 - mse: 10.3745\n",
      "Epoch 236/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.3642 - mse: 10.3642\n",
      "Epoch 237/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.3755 - mse: 10.3755\n",
      "Epoch 238/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.3733 - mse: 10.3733\n",
      "Epoch 239/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.3676 - mse: 10.3676\n",
      "Epoch 240/300\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 10.3794 - mse: 10.3794\n",
      "Epoch 241/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.3602 - mse: 10.3602\n",
      "Epoch 242/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.3823 - mse: 10.3823\n",
      "Epoch 243/300\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 10.3676 - mse: 10.3676\n",
      "Epoch 244/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3605 - mse: 10.3605\n",
      "Epoch 245/300\n",
      "47/47 [==============================] - 3s 53ms/step - loss: 10.4054 - mse: 10.4054\n",
      "Epoch 246/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3727 - mse: 10.3727\n",
      "Epoch 247/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3829 - mse: 10.3829\n",
      "Epoch 248/300\n",
      "47/47 [==============================] - 3s 53ms/step - loss: 10.3760 - mse: 10.3760\n",
      "Epoch 249/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 49ms/step - loss: 10.3706 - mse: 10.3706\n",
      "Epoch 250/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.3585 - mse: 10.3585\n",
      "Epoch 251/300\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 10.3648 - mse: 10.3648\n",
      "Epoch 252/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3604 - mse: 10.3604\n",
      "Epoch 253/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3491 - mse: 10.3491\n",
      "Epoch 254/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.4091 - mse: 10.4091: 0s - loss: 10.6046 - mse: 10.\n",
      "Epoch 255/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.3723 - mse: 10.3723\n",
      "Epoch 256/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.3986 - mse: 10.3986: 0s - loss: 10.0271 - \n",
      "Epoch 257/300\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 10.3694 - mse: 10.3694\n",
      "Epoch 258/300\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 10.3648 - mse: 10.3648\n",
      "Epoch 259/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3633 - mse: 10.3633\n",
      "Epoch 260/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.3616 - mse: 10.3616\n",
      "Epoch 261/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3775 - mse: 10.3775\n",
      "Epoch 262/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.3615 - mse: 10.3615\n",
      "Epoch 263/300\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 10.3493 - mse: 10.3493\n",
      "Epoch 264/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3628 - mse: 10.3628\n",
      "Epoch 265/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3542 - mse: 10.3542\n",
      "Epoch 266/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3494 - mse: 10.3494\n",
      "Epoch 267/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3821 - mse: 10.3821\n",
      "Epoch 268/300\n",
      "47/47 [==============================] - 3s 56ms/step - loss: 10.3583 - mse: 10.3583\n",
      "Epoch 269/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3531 - mse: 10.3531\n",
      "Epoch 270/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3547 - mse: 10.3547\n",
      "Epoch 271/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3682 - mse: 10.3682\n",
      "Epoch 272/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3614 - mse: 10.3614\n",
      "Epoch 273/300\n",
      "47/47 [==============================] - 3s 53ms/step - loss: 10.3631 - mse: 10.3631\n",
      "Epoch 274/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3617 - mse: 10.3617\n",
      "Epoch 275/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.3508 - mse: 10.3508\n",
      "Epoch 276/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3446 - mse: 10.3446\n",
      "Epoch 277/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.3460 - mse: 10.3460\n",
      "Epoch 278/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3461 - mse: 10.3461\n",
      "Epoch 279/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3534 - mse: 10.3534\n",
      "Epoch 280/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3435 - mse: 10.3435\n",
      "Epoch 281/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3624 - mse: 10.3624\n",
      "Epoch 282/300\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 10.3344 - mse: 10.3344\n",
      "Epoch 283/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.3554 - mse: 10.3554\n",
      "Epoch 284/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3429 - mse: 10.3429\n",
      "Epoch 285/300\n",
      "47/47 [==============================] - 2s 53ms/step - loss: 10.3291 - mse: 10.3291\n",
      "Epoch 286/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3346 - mse: 10.3346\n",
      "Epoch 287/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3378 - mse: 10.3378\n",
      "Epoch 288/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3482 - mse: 10.3482\n",
      "Epoch 289/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3384 - mse: 10.3384\n",
      "Epoch 290/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3321 - mse: 10.3321\n",
      "Epoch 291/300\n",
      "47/47 [==============================] - 2s 51ms/step - loss: 10.3434 - mse: 10.3434\n",
      "Epoch 292/300\n",
      "47/47 [==============================] - 3s 58ms/step - loss: 10.3491 - mse: 10.3491\n",
      "Epoch 293/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3326 - mse: 10.3326\n",
      "Epoch 294/300\n",
      "47/47 [==============================] - 3s 56ms/step - loss: 10.3358 - mse: 10.3358\n",
      "Epoch 295/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3310 - mse: 10.3310\n",
      "Epoch 296/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3379 - mse: 10.3379\n",
      "Epoch 297/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3380 - mse: 10.3380\n",
      "Epoch 298/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3417 - mse: 10.3417\n",
      "Epoch 299/300\n",
      "47/47 [==============================] - 2s 52ms/step - loss: 10.3350 - mse: 10.3350\n",
      "Epoch 300/300\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 10.3455 - mse: 10.3455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0b5c616990>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Paré el entrenamiento antes para que no se sobreajustara\n",
    "Global_model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "Global_model.fit([X_train_snr, K_mag_train_snr , X_offset_train_snr], Y_train_snr, epochs=300, batch_size=128, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_model.save('probando_rendimiento_1_SNR(4000-2000).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global_model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "#path_local = \"/home/anell/Desktop/AnellExercises/Models/\"\n",
    "\n",
    "#callbacks = [ModelCheckpoint(f'{path_local}/model_probando_rendimiento_1_SNR(4000-2000)_2.h5', verbose=1, save_best_only=True)]\n",
    "\n",
    "#Global_model.fit([X_train_snr,K_mag_train_snr,X_offset_train_snr], Y_train_snr, batch_size=128, #shuffle='batch', \n",
    "#                 epochs=300, callbacks=callbacks, \n",
    "#                 validation_data=([X_val_snr,K_mag_val_snr,X_offset_val_snr], Y_val_snr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
