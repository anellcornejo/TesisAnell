{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO 4: \n",
    "\n",
    "* Filtros: Color_BP_RP!=-9999, G_Magnitude!=-9999, Temperature_Eff!=-9999, SNR > 20\n",
    "* Random: SI\n",
    "* Funciones de act.: >PARALAJE: relu -> tanh -> relu -> tanh -> relu -> softplus\n",
    "                 >OFFSET: relu -> relu -> tanh\n",
    "* Loss: mse\n",
    "* Épocas: 200\n",
    "* Batch size: 256\n",
    "* Discriminación por SNR: SI\n",
    "* Tamaños train/cv/test: 6000(4000 buen SNR + 2000 mal SNR),2000(mal SNR),2000(mal SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv1D , Dropout , Flatten , MaxPooling1D, Dense, Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization process  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallax prediction with Optimization\n",
    "(Next to the notebook \"thesisNNtrain.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\"/home/anell/Desktop/Bovy/AnellExercises/data_matched/MatchApogeeGaia(0-28500).csv\")\n",
    "\n",
    "Parallax = np.array(Data[\"parallax\"])\n",
    "Parallax_error = np.array(Data[\"parallax_error\"])\n",
    "Corrected_magnitude = np.array(Data[\"corrected_magnitude\"])\n",
    "Spectra = fits.open('/home/anell/Desktop/Bovy/AnellExercises/data_matched/contspec_dr14(0-28500).fits')[0].data\n",
    "\n",
    "#To optimize \n",
    "SNR = np.array(Data[\"SNR\"])\n",
    "G_Magnitude = np.array(Data[\"phot_g_mean_mag\"])\n",
    "Color_BP_RP = np.array(Data[\"bp_rp\"])\n",
    "Temperature_Eff = np.array(Data[\"NN-teff\"])\n",
    "Logg = np.array(Data[\"NN-logg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idx , bad_idx=  [] , []\n",
    "for i in range(len(Temperature_Eff)):\n",
    "    if (Color_BP_RP[i] != -9999.) and (G_Magnitude[i] != -9999.) and (Temperature_Eff[i] != -9999.) and (SNR[i] > 20):# and (Parallax_error[i] / Parallax[i] < 0.1):\n",
    "        good_idx.append(i)\n",
    "    else:\n",
    "        bad_idx.append(i)\n",
    "        \n",
    "parallax = Parallax[good_idx]\n",
    "parallax_error = Parallax_error[good_idx]\n",
    "corrected_magnitude = Corrected_magnitude[good_idx]\n",
    "spectra = Spectra[good_idx]\n",
    "\n",
    "Snr = SNR[good_idx]\n",
    "G_magnitude = G_Magnitude[good_idx]\n",
    "Color_bp_rp = Color_BP_RP[good_idx]\n",
    "Temperature_eff = Temperature_Eff[good_idx]\n",
    "logg = Logg[good_idx]\n",
    "\n",
    "\n",
    "\n",
    "#Normalization to G, Color and Teff\n",
    "G_magnitude_std = np.std(G_magnitude)\n",
    "G_magnitude_mean = np.mean(G_magnitude)\n",
    "norm_G_magnitude = (G_magnitude - G_magnitude_mean) / G_magnitude_std\n",
    "\n",
    "Color_std = np.std(Color_bp_rp)\n",
    "Color_mean = np.mean(Color_bp_rp)\n",
    "norm_Color_bp_rp = (Color_bp_rp - Color_mean) / Color_std\n",
    "\n",
    "Teff_std = np.std(Temperature_eff)\n",
    "Teff_mean = np.mean(Temperature_eff)\n",
    "norm_Temperature_eff = (Temperature_eff - Teff_mean) / Teff_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_dataset(X,Y,K,offset,m,train=None, cv = None, test =None):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    X.shape = (m,7514,1)\n",
    "    Y.shape = (m,1)\n",
    "    K.shape = (m,1)\n",
    "    offset.shape = (m,3)\n",
    "    \"\"\"\n",
    "   \n",
    "    if (train == True) and (cv == True) and (test == True):\n",
    "        \n",
    "        X_train = X[:int(0.6*m),:,:]\n",
    "        Y_train = Y[:int(0.6*m)]\n",
    "        K_train = K[:int(0.6*m)]\n",
    "        offset_train = offset[:int(0.6*m)]\n",
    "    \n",
    "        X_cv = X[int(0.6*m):int(0.8*m),:,:]\n",
    "        Y_cv = Y[int(0.6*m):int(0.8*m)]\n",
    "        K_cv = K[int(0.6*m):int(0.8*m)]\n",
    "        offset_cv = offset[int(0.6*m):int(0.8*m)]\n",
    "\n",
    "        X_test = X[int(0.8*m):m,:,:]\n",
    "        Y_test = Y[int(0.8*m):m]\n",
    "        K_test = K[int(0.8*m):m]\n",
    "        offset_test = offset[int(0.8*m):m]\n",
    "        \n",
    "        #print(\"Train,CV,Test\")\n",
    "        return [X_train, Y_train, K_train, offset_train], [X_cv, Y_cv, K_cv, offset_cv],[X_test, Y_test, K_test, offset_test]\n",
    "    \n",
    "    elif (train == False) and (cv == True) and (test == True): \n",
    "    \n",
    "        X_cv = X[:int(0.2*m),:,:]\n",
    "        Y_cv = Y[:int(0.2*m)]\n",
    "        K_cv = K[:int(0.2*m)]\n",
    "        offset_cv = offset[:int(0.2*m)]\n",
    "\n",
    "        X_test = X[int(0.2*m):int(0.4*m),:,:]\n",
    "        Y_test = Y[int(0.2*m):int(0.4*m)]\n",
    "        K_test = K[int(0.2*m):int(0.4*m)]\n",
    "        offset_test = offset[int(0.2*m):int(0.4*m)]\n",
    "        \n",
    "        #print(\"CV,Test\")\n",
    "        return [X_cv, Y_cv, K_cv, offset_cv],[X_test, Y_test, K_test, offset_test]\n",
    "    \n",
    "    elif (train == True) and (cv == False) and (test == False): \n",
    "        \n",
    "        X_train = X[:int(0.6*m),:,:]\n",
    "        Y_train = Y[:int(0.6*m)]\n",
    "        K_train = K[:int(0.6*m)]\n",
    "        offset_train = offset[:int(0.6*m)]\n",
    "        \n",
    "        #print(\"Train\")\n",
    "        return [X_train, Y_train, K_train, offset_train]\n",
    "    \n",
    "###################################################################################################################\n",
    "###################################################################################################################\n",
    "\n",
    "def ApogeeDR14GaiaDR2(dim_t , dim_n): \n",
    "    \"\"\"\n",
    "    INPUT: \n",
    "    dim_t - number of time steps of spectrum \n",
    "    dim_n - number of features of spectrum\n",
    "    \"\"\"\n",
    "    \n",
    "    #SPECTRUM TO LUINOSITY\n",
    "    dim_1 = 1 # number of corrected magnitude for one example \n",
    "    units = 1 #number of final output for one example\n",
    "    inputs_spectra = Input(shape=(dim_t, dim_n)) \n",
    "    inputs_mag = Input(shape=(dim_1,), name=\"ApparentMagnitude-input\")\n",
    "    \n",
    "    x_parallax = Conv1D(filters=4, kernel_size=2, activation='relu')(inputs_spectra)\n",
    "    x_parallax = MaxPooling1D(pool_size=2)(x_parallax)\n",
    "    #x_parallax = Conv1D(filters=4, kernel_size=2, activation='relu')(x_parallax)\n",
    "    #x_parallax = MaxPooling1D(pool_size=2)(x_parallax)\n",
    "    x_parallax = Flatten()(x_parallax)\n",
    "    x_parallax = Dense(164, activation='relu')(x_parallax) \n",
    "    x_parallax = Dense(164, activation='tanh')(x_parallax) #tanh\n",
    "    x_parallax = Dense(64, activation='relu')(x_parallax) \n",
    "    x_parallax = Dense(64, activation='tanh')(x_parallax)\n",
    "    x_parallax = Dense(32, activation='relu')(x_parallax)\n",
    "    #x_parallax = Dense(16, activation='tanh')(x_parallax)\n",
    "    x_parallax = Dense(units, activation='softplus')(x_parallax)\n",
    "    \n",
    "    outputs_parallax = Lambda(lambda function: tf.math.multiply(function[0], tf.math.pow(10., \n",
    "                              tf.math.multiply(-0.2, function[1]))),\n",
    "                              name='luminosity-to-parallax')([x_parallax, inputs_mag])\n",
    "   \n",
    "    #OFFSET CORRECTION : (optimization)\n",
    "    inputs_offset = Input(shape=(3,), name=\"Offset-input\")\n",
    "    x_offset = Dense(64, activation='relu')(inputs_offset)\n",
    "    x_offset = Dense(32, activation='relu')(inputs_offset) \n",
    "    #x_offset = Dense(16, activation='relu')(x_offset)\n",
    "    x_offset = Dense(units, activation='tanh')(x_offset) \n",
    "    \n",
    "    outputs_parallax_with_offset = Lambda(lambda function: tf.math.add(function[0], function[1]),\n",
    "                                          name=\"Sum-parallax-offset\")([outputs_parallax, x_offset]) \n",
    "    \n",
    "    #Model setup\n",
    "    #model =  Model(inputs = [inputs_spectra,inputs_mag],outputs = [outputs_parallax])\n",
    "    model =  Model(inputs = [inputs_spectra,inputs_mag, inputs_offset],outputs = [outputs_parallax_with_offset])\n",
    "    \n",
    "    return model \n",
    "\n",
    "###################################################################################################################\n",
    "###################################################################################################################\n",
    "\n",
    "def visualization(Y_train , preds_train , Y_cv = None , preds_cv = None,Y_test = None,preds_test = None):\n",
    "    \n",
    "    #if (Y_cv != None) and (preds_cv != None) and (Y_test != None) and (preds_test != None):\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=3,figsize=(15, 4)) \n",
    "\n",
    "        axs[0].scatter(Y_train, preds_train,color = \"maroon\",s = 4)\n",
    "        axs[1].scatter(Y_cv, preds_cv,color = \"maroon\",s = 4)\n",
    "        axs[2].scatter(Y_test, preds_test,color = \"maroon\",s = 4)\n",
    "        axs[0].set_title('Gaia parallax vs NN parallax of Train set')\n",
    "        axs[1].set_title('Gaia parallax vs NN parallax of CV set')\n",
    "        axs[2].set_title('Gaia parallax vs NN parallax of Test set')\n",
    "        axs[0].set_xlabel(\"Paralaje de Gaia\")\n",
    "        axs[0].set_ylabel(\"Paralaje de NN\")\n",
    "        axs[1].set_xlabel(\"Paralaje de Gaia\")\n",
    "        axs[1].set_ylabel(\"Paralaje de NN\")\n",
    "        axs[2].set_xlabel(\"Paralaje de Gaia\")\n",
    "        axs[2].set_ylabel(\"Paralaje de NN\")\n",
    "\n",
    "        #Linear regression:\n",
    "        def Reshape(lista):\n",
    "            l = []\n",
    "            for i in range(len(lista)):\n",
    "                l.append(lista[i][0])\n",
    "            return l\n",
    "\n",
    "        Y_train_reshape = np.array(Reshape(Y_train))\n",
    "        preds_train_reshape = np.array(Reshape(preds_train))\n",
    "        m_train, b_train = np.polyfit(Y_train_reshape, preds_train_reshape, 1)\n",
    "        r2_train = r2_score(Y_train_reshape, preds_train_reshape)\n",
    "        axs[0].plot(Y_train, m_train*Y_train_reshape + b_train, c = \"goldenrod\")\n",
    "        axs[0].legend([f\"m: {round(m_train,2)}, \\n r2: {round(r2_train,2)}\",\"sample\"])\n",
    "\n",
    "        Y_cv_reshape = np.array(Reshape(Y_cv))\n",
    "        preds_cv_reshape = np.array(Reshape(preds_cv))\n",
    "        m_cv, b_cv = np.polyfit(Y_cv_reshape, preds_cv_reshape, 1)\n",
    "        r2_cv = r2_score(Y_cv_reshape, preds_cv_reshape)\n",
    "        axs[1].plot(Y_cv, m_cv*Y_cv_reshape + b_cv, c = \"goldenrod\")\n",
    "        axs[1].legend([f\"m: {round(m_cv,2)}, \\n r2: {round(r2_cv,2)}\",\"sample\"])\n",
    "\n",
    "        Y_test_reshape = np.array(Reshape(Y_test))\n",
    "        preds_test_reshape = np.array(Reshape(preds_test))\n",
    "        m_test, b_test = np.polyfit(Y_test_reshape, preds_test_reshape, 1)\n",
    "        r2_test = r2_score(Y_test_reshape, preds_test_reshape)\n",
    "        axs[2].plot(Y_test, m_test*Y_test_reshape + b_test, c = \"goldenrod\")\n",
    "        axs[2].legend([f\"m: {round(m_test,2)}, \\n r2: {round(r2_test,2)}\",\"sample\"])\n",
    "        plt.show()\n",
    "\n",
    "        print(\"tamaño set entrenaiento: \", len(Y_train_reshape), \"\\n\", \"tamaño cv set: \", len(Y_cv_reshape), \"\\n\", \n",
    "              \"tamaño set de testeo: \", len(Y_test_reshape))\n",
    "    \n",
    "    #else:\n",
    "    #   fig = plt.subplots(nrows=1, ncols=1,figsize=(10, 4))\n",
    "    #    plt.scatter(Y_train, preds_train,color = \"maroon\",s = 2)\n",
    "    #    plt.title('Gaia parallax vs NN parallax of Train set')\n",
    "    #    plt.xlabel(\"Paralaje de Gaia\")\n",
    "    #    plt.ylabel(\"Paralaje de NN\")\n",
    "        \n",
    "        #Linear regression:\n",
    "    #    def Reshape(lista):\n",
    "    #        l = []\n",
    "    #        for i in range(len(lista)):\n",
    "    #            l.append(lista[i][0])\n",
    "    #        return l\n",
    "\n",
    "    #    Y_train_reshape = np.array(Reshape(Y_train))\n",
    "    #    preds_train_reshape = np.array(Reshape(preds_train))\n",
    "    #    m_train, b_train = np.polyfit(Y_train_reshape, preds_train_reshape, 1)\n",
    "    #    r2_train = r2_score(Y_train_reshape, preds_train_reshape)\n",
    "    #    plt.plot(Y_train, m_train*Y_train_reshape + b_train, color = \"goldenrod\")\n",
    "    #    plt.legend([f\"m: {round(m_train,2)}, \\n r2: {round(r2_train,2)}\",\"sample\"])\n",
    "    #    plt.show()\n",
    "\n",
    "    \n",
    "###################################################################################################################\n",
    "###################################################################################################################\n",
    "    \n",
    "def custom_loss_function(y,y_hat,y_error,y_hat_error):\n",
    "    s = np.log(y_error**2 + y_hat_error**2 )\n",
    "    J = ((1/2)*(y-y_hat)*(y-y_hat)*np.e**(-s)) + (1/2)*s\n",
    "    return sum(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension correction\n",
    "X = np.expand_dims(spectra,axis = 2)\n",
    "Y = np.expand_dims(parallax,axis=1)\n",
    "Y_error = np.expand_dims(parallax_error,axis=1)\n",
    "Mag = np.expand_dims(corrected_magnitude,axis=1)\n",
    "\n",
    "G_mag = np.expand_dims(norm_G_magnitude,axis=1)\n",
    "bp_rp = np.expand_dims(norm_Color_bp_rp,axis=1)\n",
    "teff = np.expand_dims(norm_Temperature_eff,axis=1)\n",
    "X_offset = np.concatenate((G_mag, bp_rp , teff), axis = 1) \n",
    "\n",
    "Snr = np.expand_dims(Snr,axis=1)\n",
    "logg = np.expand_dims(logg,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To randomize the data set\n",
    "idx = []\n",
    "for i in range(len(X)):\n",
    "    idx.append(i)\n",
    "random.seed(20)\n",
    "random.shuffle(idx)\n",
    "\n",
    "X = X[idx]              # shape: (9757, 7514 , 1)   \n",
    "Y = Y[idx]              # shape: (9757, 1)  \n",
    "Mag = Mag[idx]          # shape: (9757, 1) \n",
    "X_offset = X_offset[idx]# shape: (9757, 3)\n",
    "snr = Snr[idx]\n",
    "logg = logg[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To SNR discrimination\n",
    "idx_good_snr = []\n",
    "idx_bad_snr = []\n",
    "\n",
    "for i in range(len(Snr)):\n",
    "    if Snr[i] >= 200:\n",
    "        idx_good_snr.append(i)\n",
    "    else:\n",
    "        idx_bad_snr.append(i)\n",
    "    \n",
    "X_good_snr = X[idx_good_snr][5000:]\n",
    "X_bad_snr = X[idx_bad_snr][5000:]\n",
    "Y_good_snr = Y[idx_good_snr][5000:]\n",
    "Y_bad_snr = Y[idx_bad_snr][5000:]\n",
    "Mag_good_snr = Mag[idx_good_snr][5000:]\n",
    "Mag_bad_snr = Mag[idx_bad_snr][5000:]\n",
    "X_offset_good_snr = X_offset[idx_good_snr][5000:]\n",
    "X_offset_bad_snr = X_offset[idx_bad_snr][5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9400, 9069, 28469)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_good_snr), len(X_bad_snr), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 1), (2000, 1), (2000, 1), (6000, 1), (2000, 1), (2000, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN , CV , TEST = size_dataset(X,Y,Mag,X_offset,10000,True, True, True)\n",
    "TRAIN_SNR =  size_dataset(X_good_snr,Y_good_snr,Mag_good_snr,X_offset_good_snr,10000, True, False, False)\n",
    "CV_SNR, TEST_SNR = size_dataset(X_bad_snr,Y_bad_snr,Mag_bad_snr,X_offset_bad_snr,10000, False, True, True)\n",
    "\n",
    "X_train, Y_train , Mag_train , X_offset_train = TRAIN\n",
    "X_cv, Y_cv , Mag_cv , XÇ_offset_cv = CV\n",
    "X_test, Y_test , Mag_test , X_offset_test = TEST\n",
    "\n",
    "X_train_snr, Y_train_snr , Mag_train_snr , X_offset_train_snr = TRAIN_SNR\n",
    "X_cv_snr, Y_cv_snr , Mag_cv_snr , X_offset_cv_snr = CV_SNR\n",
    "X_test_snr, Y_test_snr , Mag_test_snr , X_offset_test_snr = TEST_SNR\n",
    "\n",
    "Y_train.shape, Y_cv.shape,Y_test.shape,Y_train_snr.shape, Y_cv_snr.shape,Y_test_snr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9069, 7514, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bad_snr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = np.concatenate((X_good_snr[:4000],X_bad_snr[:2000]),axis = 0)\n",
    "YY = np.concatenate((Y_good_snr[:4000],Y_bad_snr[:2000]),axis = 0)\n",
    "MAGG = np.concatenate((Mag_good_snr[:4000],Mag_bad_snr[:2000]),axis = 0)\n",
    "OFF = np.concatenate((X_offset_good_snr[:4000],X_offset_bad_snr[:2000]),axis = 0)\n",
    "\n",
    "XX_CV = X_bad_snr[2000:4000]\n",
    "YY_CV = Y_bad_snr[2000:4000]\n",
    "MAGG_CV = Mag_bad_snr[2000:4000]\n",
    "OFF_CV = X_offset_bad_snr[2000:4000]\n",
    "\n",
    "XX_TEST = X_bad_snr[4000:6000]\n",
    "YY_TEST = Y_bad_snr[4000:6000]\n",
    "MAGG_TEST = Mag_bad_snr[4000:6000]\n",
    "OFF_TEST = X_offset_bad_snr[4000:6000]\n",
    "\n",
    "\n",
    "I = []\n",
    "for i in range(len(XX)):\n",
    "    I.append(i)\n",
    "random.seed(1000)\n",
    "random.shuffle(I)\n",
    "\n",
    "XX = XX[I]\n",
    "YY = YY[I]\n",
    "MAGG = MAGG[I]\n",
    "OFF = OFF[I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 7514, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 7513, 4)      12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 3756, 4)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 15024)        0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 164)          2464100     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 164)          27060       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           10560       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           4160        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Offset-input (InputLayer)       [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            33          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ApparentMagnitude-input (InputL [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           128         Offset-input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "luminosity-to-parallax (Lambda) (None, 1)            0           dense_5[0][0]                    \n",
      "                                                                 ApparentMagnitude-input[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            33          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Sum-parallax-offset (Lambda)    (None, 1)            0           luminosity-to-parallax[0][0]     \n",
      "                                                                 dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,508,166\n",
      "Trainable params: 2,508,166\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_features = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "Global_model = ApogeeDR14GaiaDR2(n_timesteps , n_features)\n",
    "\n",
    "Global_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.11) \n",
    "\n",
    "Global_model.compile(optimizer='adam', loss='mse', metrics=['mse'])   #mse o mae\n",
    "#Global_model.compile(optimizer='adam', loss=custom_loss_function(Y_train,preds_train,Y_error,preds_error), \n",
    "                     #metrics=['mse'])   #mse o mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 6.5912 - mse: 6.5912\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 10s 399ms/step - loss: 5.8595 - mse: 5.8595\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.5128 - mse: 5.5128\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 5.4066 - mse: 5.4066\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 5.3635 - mse: 5.3635\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 5.3421 - mse: 5.3421\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 5.3264 - mse: 5.3264\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 5.3152 - mse: 5.3152\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 5.3051 - mse: 5.3051\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.2952 - mse: 5.2952\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 2s 88ms/step - loss: 5.2876 - mse: 5.2876\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 5.2809 - mse: 5.2809\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 5.2737 - mse: 5.2737\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.2684 - mse: 5.2684\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 5.2637 - mse: 5.2637\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 5.2579 - mse: 5.2579\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 3s 125ms/step - loss: 5.2543 - mse: 5.2543\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 2s 94ms/step - loss: 5.2498 - mse: 5.2498\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 5.2454 - mse: 5.2454\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.2422 - mse: 5.2422\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 5.2401 - mse: 5.2401\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 5.2352 - mse: 5.2352\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.2321 - mse: 5.2321\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.2292 - mse: 5.2292\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.2262 - mse: 5.2262\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 5.2250 - mse: 5.2250\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.2222 - mse: 5.2222\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.2181 - mse: 5.2181\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.2166 - mse: 5.2166\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.2142 - mse: 5.2142\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.2099 - mse: 5.2099\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.2072 - mse: 5.2072\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.2067 - mse: 5.2067\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.2037 - mse: 5.2037\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.2014 - mse: 5.2014\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.2002 - mse: 5.2002\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1967 - mse: 5.1967\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1949 - mse: 5.1949\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1931 - mse: 5.1931\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1914 - mse: 5.1914\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1889 - mse: 5.1889\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1870 - mse: 5.1870\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1865 - mse: 5.1865\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1838 - mse: 5.1838\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1829 - mse: 5.1829\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1813 - mse: 5.1813\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1801 - mse: 5.1801\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1786 - mse: 5.1786\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1767 - mse: 5.1767\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1769 - mse: 5.1769\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1738 - mse: 5.1738\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1726 - mse: 5.1726\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1719 - mse: 5.1719\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1698 - mse: 5.1698\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1700 - mse: 5.1700\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1680 - mse: 5.1680\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 5.1677 - mse: 5.1677\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1657 - mse: 5.1657\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1643 - mse: 5.1643\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1638 - mse: 5.1638\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1627 - mse: 5.1627\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1616 - mse: 5.1616\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1600 - mse: 5.1600\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1599 - mse: 5.1599\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1575 - mse: 5.1575\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 5.1608 - mse: 5.1608\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1579 - mse: 5.1579\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1553 - mse: 5.1553\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1559 - mse: 5.1559\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1500 - mse: 5.1500\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1537 - mse: 5.1537\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1523 - mse: 5.1523\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1529 - mse: 5.1529\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1489 - mse: 5.1489\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1476 - mse: 5.1476\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1485 - mse: 5.1485\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1477 - mse: 5.1477\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1473 - mse: 5.1473\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1447 - mse: 5.1447\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1437 - mse: 5.1437\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1437 - mse: 5.1437\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1427 - mse: 5.1427\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1422 - mse: 5.1422\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1411 - mse: 5.1411\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1400 - mse: 5.1400\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1392 - mse: 5.1392\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1368 - mse: 5.1368\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1313 - mse: 5.1313\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1353 - mse: 5.1353\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1367 - mse: 5.1367\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1345 - mse: 5.1345\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 5.1363 - mse: 5.1363\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1349 - mse: 5.1349\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1333 - mse: 5.1333\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1341 - mse: 5.1341\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1300 - mse: 5.1300\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.1263 - mse: 5.1263\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 5.1189 - mse: 5.1189\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 5.1097 - mse: 5.1097\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 5.0633 - mse: 5.0633\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 4.8598 - mse: 4.8598\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 4.5442 - mse: 4.5442\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 4.1861 - mse: 4.1861\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 3.8583 - mse: 3.8583\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 3.6020 - mse: 3.6020\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 3.3424 - mse: 3.3424\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 3.0993 - mse: 3.0993\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 2.8902 - mse: 2.8902\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 2.7483 - mse: 2.7483\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 2.5531 - mse: 2.5531\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 2.4011 - mse: 2.4011\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 2.2688 - mse: 2.2688\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 2.1792 - mse: 2.1792\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 2.0786 - mse: 2.0786\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 1.9923 - mse: 1.9923\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 1.9058 - mse: 1.9058\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 1.7950 - mse: 1.7950\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 2s 88ms/step - loss: 1.6973 - mse: 1.6973\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 1.5991 - mse: 1.5991\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 3s 130ms/step - loss: 1.5165 - mse: 1.5165\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 1.4471 - mse: 1.4471\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 2s 94ms/step - loss: 1.3933 - mse: 1.3933\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 1.3406 - mse: 1.3406\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 3s 120ms/step - loss: 1.3108 - mse: 1.3108\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 1.2480 - mse: 1.2480\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 1.2081 - mse: 1.2081\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 1.1688 - mse: 1.1688\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 3s 107ms/step - loss: 1.1354 - mse: 1.1354\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 1.0960 - mse: 1.0960\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 1.0637 - mse: 1.0637\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 1.0375 - mse: 1.0375\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 1.0124 - mse: 1.0124\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.9789 - mse: 0.9789\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.9559 - mse: 0.9559\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.9347 - mse: 0.9347\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.9218 - mse: 0.9218\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.8932 - mse: 0.8932\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.8692 - mse: 0.8692\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.8485 - mse: 0.8485\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.8335 - mse: 0.8335\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.8229 - mse: 0.8229\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.8081 - mse: 0.8081\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.7905 - mse: 0.7905\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.7775 - mse: 0.7775\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.7668 - mse: 0.7668\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.7529 - mse: 0.7529\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.7411 - mse: 0.7411\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.7304 - mse: 0.7304\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.7200 - mse: 0.7200\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.7103 - mse: 0.7103\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.7024 - mse: 0.7024\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.7130 - mse: 0.7130\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.7051 - mse: 0.7051\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.6845 - mse: 0.6845\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.6730 - mse: 0.6730\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.6644 - mse: 0.6644\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.6580 - mse: 0.6580\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.6664 - mse: 0.6664\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.6552 - mse: 0.6552\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.6176 - mse: 0.6176\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.5617 - mse: 0.5617\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.5340 - mse: 0.5340\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.5144 - mse: 0.5144\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.4921 - mse: 0.4921\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.4857 - mse: 0.4857\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.4517 - mse: 0.4517\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.4285 - mse: 0.4285\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.4052 - mse: 0.4052\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.3850 - mse: 0.3850\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 82ms/step - loss: 0.3698 - mse: 0.3698\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.3584 - mse: 0.3584\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.3469 - mse: 0.3469\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.3390 - mse: 0.3390\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.3269 - mse: 0.3269\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.3167 - mse: 0.3167\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.3086 - mse: 0.3086\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.3016 - mse: 0.3016\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.2898 - mse: 0.2898\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.2836 - mse: 0.2836\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.2735 - mse: 0.2735\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.2652 - mse: 0.2652\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.2601 - mse: 0.2601\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.2672 - mse: 0.2672\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.2507 - mse: 0.2507\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.2373 - mse: 0.2373\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.2297 - mse: 0.2297\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.2218 - mse: 0.2218\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.2162 - mse: 0.2162\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.2095 - mse: 0.2095\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.2035 - mse: 0.2035\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 3s 124ms/step - loss: 0.1969 - mse: 0.1969\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.1870 - mse: 0.1870\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.1811 - mse: 0.1811\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.1756 - mse: 0.1756\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.1689 - mse: 0.1689\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.1655 - mse: 0.1655\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.1610 - mse: 0.1610\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.1551 - mse: 0.1551\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.1501 - mse: 0.1501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6c119f5810>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Global_model.fit([XX, MAGG , OFF], (YY), epochs=200, batch_size=256, verbose=1)\n",
    "\n",
    "#Global_model.fit([X_train, Mag_train , X_offset_train], (Y_train), epochs=200, batch_size=1024, verbose=1)\n",
    "\n",
    "#Global_model.fit([X_train_snr, Mag_train_snr , X_offset_train_snr], Y_train_snr, epochs=200, batch_size=512, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_train = Global_model.predict([X_train,Mag_train,X_offset_train])\n",
    "#preds_cv = Global_model.predict([X_cv,Mag_cv,X_offset_cv])\n",
    "#preds_test = Global_model.predict([X_test,Mag_test,X_offset_test])\n",
    "\n",
    "#preds_train_snr = Global_model.predict([X_train_snr,Mag_train_snr,X_offset_train_snr])\n",
    "#preds_cv_snr = Global_model.predict([X_cv_snr,Mag_cv_snr,X_offset_cv_snr])\n",
    "#preds_test_snr = Global_model.predict([X_test_snr,Mag_test_snr,X_offset_test_snr])\n",
    "\n",
    "pp_TRAIN = Global_model.predict([XX,MAGG,OFF])\n",
    "pp_CV = Global_model.predict([XX_CV,MAGG_CV,OFF_CV])\n",
    "pp_TEST = Global_model.predict([XX_TEST,MAGG_TEST,OFF_TEST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño set entrenaiento:  6000 \n",
      " tamaño cv set:  2000 \n",
      " tamaño set de testeo:  2000\n"
     ]
    }
   ],
   "source": [
    "#visualization(Y_train , preds_train , Y_cv , preds_cv,Y_test,preds_test)\n",
    "\n",
    "#visualization(Y_train_snr , preds_train_snr , Y_cv_snr , preds_cv_snr , Y_test_snr , preds_test_snr)\n",
    "\n",
    "visualization(YY , pp_TRAIN, YY_TEST , pp_TEST , YY_CV , pp_CV )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error_train = np.abs(Y_train-preds_train) / Y_train *100\n",
    "#error_cv = np.abs(Y_cv-preds_cv) / Y_cv *100\n",
    "\n",
    "#error_train_snr = np.abs( Y_train_snr - preds_train_snr ) / (np.abs(Y_train_snr)) *100\n",
    "#error_cv_snr = np.abs(Y_cv_snr - preds_cv_snr) / (np.abs(Y_cv_snr)) *100\n",
    "#error_test_snr = np.abs(Y_test_snr - preds_test_snr) / (np.abs(Y_test_snr)) *100\n",
    "\n",
    "ERROR_train = np.abs( YY - pp_TRAIN ) / (np.abs(YY)) *100\n",
    "ERROR_cv = np.abs(YY_CV - pp_CV) / (np.abs(YY_CV)) *100\n",
    "ERROR_test = np.abs(YY_TEST - pp_TEST) / (np.abs(YY_TEST)) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([43.65851356]), array([125.60883986]), array([85.67442929]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean_error_train = sum(np.abs(error_train))/len(error_train)\n",
    "#mean_error_cv = sum(np.abs(error_cv))/len(error_cv)\n",
    "#mean_error_train , mean_error_cv\n",
    "\n",
    "#mean_error_train_snr = sum(np.abs(error_train_snr))/len(error_train_snr)\n",
    "#mean_error_cv_snr = sum(np.abs(error_cv_snr))/len(error_cv_snr)\n",
    "#mean_error_test_snr = sum(np.abs(error_test_snr))/len(error_test_snr)\n",
    "#mean_error_train_snr , mean_error_cv_snr, mean_error_test_snr\n",
    "\n",
    "MEAN_error_train = sum(np.abs(ERROR_train))/len(ERROR_train)\n",
    "MEAN_error_cv = sum(np.abs(ERROR_cv))/len(ERROR_cv)\n",
    "MEAN_error_test = sum(np.abs(ERROR_test))/len(ERROR_test)\n",
    "MEAN_error_train , MEAN_error_cv, MEAN_error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1284 - mse: 0.1284\n",
      "MSE train: 0.13\n"
     ]
    }
   ],
   "source": [
    "#J_train, mse_train = Global_model.evaluate([X_train,Mag_train,X_offset_train], Y_train)\n",
    "#print('MSE train: %.2f' % (mse_train))\n",
    "\n",
    "#J_train, mse_train = Global_model.evaluate([X_train_snr,Mag_train_snr,X_offset_train_snr], Y_train_snr)\n",
    "#print('MSE train: %.2f' % (mse_train))\n",
    "\n",
    "J_train, mse_train = Global_model.evaluate([XX,MAGG,OFF], YY)\n",
    "print('MSE train: %.2f' % (mse_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 6ms/step - loss: 1384.8292 - mse: 1384.8292\n",
      "MSE cv: 1384.83\n"
     ]
    }
   ],
   "source": [
    "#J_cv, mse_cv = Global_model.evaluate([X_cv,Mag_cv,X_offset_cv], Y_cv)\n",
    "#print('MSE test: %.2f' % (mse_cv))\n",
    "\n",
    "#J_cv, mse_cv = Global_model.evaluate([X_cv_snr,Mag_cv_snr,X_offset_cv_snr], Y_cv_snr)\n",
    "#print('MSE cv: %.2f' % (mse_cv))\n",
    "\n",
    "J_cv, mse_cv = Global_model.evaluate([XX_CV,MAGG_CV,OFF_CV], YY_CV)\n",
    "print('MSE cv: %.2f' % (mse_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 6ms/step - loss: 32.4127 - mse: 32.4127\n",
      "MSE test: 32.41\n"
     ]
    }
   ],
   "source": [
    "#J_test, mse_test = Global_model.evaluate([X_test,Mag_test,X_offset_test], Y_test)\n",
    "#print('MSE test: %.2f' % (mse_cv))\n",
    "\n",
    "#J_test, mse_test = Global_model.evaluate([X_test_snr,Mag_test_snr,X_offset_test_snr], Y_test_snr)\n",
    "#print('MSE test: %.2f' % (mse_test))\n",
    "\n",
    "J_test, mse_test = Global_model.evaluate([XX_TEST,MAGG_TEST,OFF_TEST], YY_TEST)\n",
    "print('MSE test: %.2f' % (mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OJO CAMBIARÉ EL CV SET POR EL TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
