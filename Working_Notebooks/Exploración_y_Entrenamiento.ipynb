{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping , ReduceLROnPlateau , ModelCheckpoint\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv1D , Dropout , Flatten , MaxPooling1D, Dense, Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import random\n",
    "import h5py\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga y orden de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anell/anaconda3/envs/python37-astronn/lib/python3.7/site-packages/ipykernel_launcher.py:2: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos\n",
    "with h5py.File('/home/anell/Desktop/Bovy/AnellExercises/Fits_files/apogeedr14_gaiadr2_with_spectrum.h5') as F:  # ensure the file will be cleaned up\n",
    "    parallax = np.array(F['parallax'])\n",
    "    parallax_error = np.array(F['parallax_err'])\n",
    "    spectra = np.array(F['spectra'])\n",
    "    Kcorr = np.array(F['corrected_magnitude_K'])  # extinction corrected Ks\n",
    "    bp_rp = np.array(F['bp_rp'])\n",
    "    phot_g_mean_mag = np.array(F['phot_g_mean_mag'])\n",
    "    teff = np.array(F['NN_teff'])\n",
    "    apogee_id = np.array(F['APOGEE_ID'])\n",
    "    snr = np.array(F['SNR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60986, (60986,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bp_rp), parallax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos \n",
    "phot_g_mean_mag_std = np.std(phot_g_mean_mag)\n",
    "phot_g_mean_mag_mean = np.mean(phot_g_mean_mag)\n",
    "norm_phot_g_mean_mag = (phot_g_mean_mag - phot_g_mean_mag_mean) / phot_g_mean_mag_std\n",
    "\n",
    "bp_rp_std = np.std(bp_rp)\n",
    "bp_rp_mean = np.mean(bp_rp)\n",
    "norm_bp_rp = (bp_rp - bp_rp_mean) / bp_rp_std\n",
    "\n",
    "teff_std = np.std(teff)\n",
    "teff_mean = np.mean(teff)\n",
    "norm_teff = (teff - teff_mean) / teff_std\n",
    "\n",
    "\n",
    "#EStablecemos las variables que entrarán a la red y corregimos sus dimensiones\n",
    "X = np.expand_dims(spectra,axis = 2)\n",
    "Y = np.expand_dims(parallax,axis=1)\n",
    "Y_error = np.expand_dims(parallax_error,axis=1)\n",
    "K_mag = np.expand_dims(Kcorr,axis=1)\n",
    "G_mag = np.expand_dims(norm_phot_g_mean_mag,axis=1)\n",
    "Bp_Rp = np.expand_dims(norm_bp_rp,axis=1)\n",
    "Teff = np.expand_dims(norm_teff,axis=1)\n",
    "Snr = np.expand_dims(snr,axis=1)\n",
    "\n",
    "X_offset = np.concatenate((G_mag, Bp_Rp , Teff), axis = 1) \n",
    "\n",
    "\n",
    "#Aleatorizamos la muestra\n",
    "idx = []\n",
    "for i in range(len(X)):\n",
    "    idx.append(i)\n",
    "random.seed(20)\n",
    "random.shuffle(idx)\n",
    "\n",
    "X = X[idx]                  # shape: (60986, 7514 , 1)   \n",
    "Y = Y[idx]                  # shape: (60986, 1)  \n",
    "K_mag = K_mag[idx]          # shape: (60986, 1) \n",
    "X_offset = X_offset[idx]    # shape: (60986, 3)\n",
    "SNR = Snr[idx]              # shape: (60986, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60986, 7514, 1), (60986, 1), (60986, 1), (60986, 3), (60986, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, K_mag.shape, X_offset.shape , SNR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27721, 33265)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Corte por buena o mala relación señal a ruido\n",
    "idx_snr_good = []\n",
    "idx_snr_bad = []\n",
    "for i in range(len(SNR)):\n",
    "    if snr[i] >= 200:\n",
    "        idx_snr_good.append(i)\n",
    "    else:\n",
    "        idx_snr_bad.append(i)\n",
    "\n",
    "len(idx_snr_good), len(idx_snr_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_dataset(X , Y , K_mag , X_offset , idx_snr_good, idx_snr_bad, m = None ):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    X.shape = (_ , 7514 , 1)\n",
    "    Y.shape = (_ , 1)\n",
    "    K_mag.shape = (_ , 1)\n",
    "    X_offset.shape = (_ , 3)\n",
    "    \"\"\"\n",
    "    if m == None:\n",
    "        m = len(Y)\n",
    "    \n",
    "    X_train = np.concatenate((X[idx_snr_good][:int(0.4*m)],X[idx_snr_bad][:int(0.2*m)]),axis = 0)\n",
    "    Y_train = np.concatenate((Y[idx_snr_good][:int(0.4*m)],Y[idx_snr_bad][:int(0.2*m)]),axis = 0)\n",
    "    K_mag_train = np.concatenate((K_mag[idx_snr_good][:int(0.4*m)],K_mag[idx_snr_bad][:int(0.2*m)]),axis = 0)\n",
    "    X_offset_train = np.concatenate((X_offset[idx_snr_good][:int(0.4*m)],X_offset[idx_snr_good][:int(0.2*m)]),axis = 0)\n",
    "        \n",
    "    X_val = np.concatenate((X[idx_snr_good][int(0.4*m):int(0.6*m)],X[idx_snr_bad][int(0.4*m):int(0.5*m)]),axis = 0)\n",
    "    Y_val = np.concatenate((Y[idx_snr_good][int(0.4*m):int(0.6*m)],Y[idx_snr_bad][int(0.4*m):int(0.5*m)]),axis = 0)\n",
    "    K_mag_val = np.concatenate((K_mag[idx_snr_good][int(0.4*m):int(0.6*m)],K_mag[idx_snr_bad][int(0.4*m):int(0.5*m)]),axis = 0)\n",
    "    X_offset_val = np.concatenate((X_offset[idx_snr_good][int(0.4*m):int(0.6*m)],X_offset[idx_snr_bad][int(0.4*m):int(0.5*m)]),axis = 0)\n",
    "        \n",
    "    X_test = X[idx_snr_bad][int(0.5*m):int(m)]\n",
    "    Y_test = Y[idx_snr_bad][int(0.5*m):int(m)]\n",
    "    K_mag_test = K_mag[idx_snr_bad][int(0.5*m):int(m)]\n",
    "    X_offset_test = X_offset[idx_snr_bad][int(0.5*m):int(m)]\n",
    "    \n",
    "    #Aleatorizamos las variables:\n",
    "    idx_train = []\n",
    "    for i in range(len(X_train)):\n",
    "        idx_train.append(i)\n",
    "    random.seed(50)\n",
    "    random.shuffle(idx_train)\n",
    "    \n",
    "    idx_val = []\n",
    "    for j in range(len(X_val)):\n",
    "        idx_val.append(j)\n",
    "    random.seed(100)\n",
    "    random.shuffle(idx_val) \n",
    "    \n",
    "    X_train = X_train[idx_train]\n",
    "    Y_train = Y_train[idx_train]\n",
    "    K_mag_train = K_mag_train[idx_train]\n",
    "    X_offset_train = X_offset_train[idx_train]\n",
    "        \n",
    "    X_val = X_val[idx_val]\n",
    "    Y_val = Y_val[idx_val]\n",
    "    K_mag_val = K_mag_val[idx_val]\n",
    "    X_offset_val = X_offset_val[idx_val]\n",
    "    \n",
    "\n",
    "    return ([X_train, Y_train, K_mag_train, X_offset_train], [X_val, Y_val, K_mag_val, X_offset_val],\n",
    "            [X_test, Y_test, K_mag_test, X_offset_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establecemos los sets de entrenaiento, de validación y de testeo\n",
    "TRAIN,VAL,TEST = size_dataset(X , Y , K_mag , X_offset , idx_snr_good, idx_snr_bad, m = 10000 )\n",
    "\n",
    "X_train, Y_train, K_mag_train, X_offset_train = TRAIN\n",
    "X_val, Y_val, K_mag_val, X_offset_val = VAL\n",
    "X_test, Y_test, K_mag_test, X_offset_test = TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 7514, 1), (3000, 7514, 1), (5000, 7514, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_val.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación del modelo y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApogeeDR14GaiaDR2(dim_t , dim_n): \n",
    "    \"\"\"\n",
    "    INPUT: \n",
    "    dim_t - number of time steps of spectrum \n",
    "    dim_n - number of features of spectrum\n",
    "    \"\"\"\n",
    "    \n",
    "    #SPECTRUM TO LUINOSITY\n",
    "    dim_1 = 1 # number of corrected magnitude for one example \n",
    "    units = 1 #number of final output for one example\n",
    "    inputs_spectra = Input(shape=(dim_t, dim_n)) \n",
    "    inputs_mag = Input(shape=(dim_1,), name=\"ApparentMagnitude-input\")\n",
    "    \n",
    "    x_parallax = Conv1D(filters=4, kernel_size=3, activation='relu')(inputs_spectra)\n",
    "    x_parallax = MaxPooling1D(pool_size=2)(x_parallax)\n",
    "    x_parallax = Flatten()(x_parallax)\n",
    "    x_parallax = Dense(128, activation='tanh')(x_parallax) \n",
    "    x_parallax = Dense(64, activation='relu')(x_parallax) \n",
    "    x_parallax = Dense(32, activation='tanh')(x_parallax)\n",
    "    x_parallax = Dense(16, activation='relu')(x_parallax)\n",
    "    x_parallax = Dense(units, activation='softplus')(x_parallax)\n",
    "    \n",
    "    outputs_parallax = Lambda(lambda function: tf.math.multiply(function[0], tf.math.pow(10., \n",
    "                              tf.math.multiply(-0.2, function[1]))),\n",
    "                              name='Output-physical-parallax')([x_parallax, inputs_mag])\n",
    "   \n",
    "    #OFFSET CORRECTION : (optimization)\n",
    "    inputs_offset = Input(shape=(3,), name=\"Offset-input\")\n",
    "    x_offset = Dense(32, activation='relu')(inputs_offset) \n",
    "    x_offset = Dense(16, activation='relu')(x_offset)\n",
    "    x_offset = Dense(units, activation='tanh')(x_offset) \n",
    "    \n",
    "    outputs_parallax_with_offset = Lambda(lambda function: tf.math.add(function[0], function[1]),\n",
    "                                          name=\"Output-parallax-with-offset\")([outputs_parallax, x_offset]) \n",
    "    \n",
    "    #Model setup\n",
    "    model =  Model(inputs = [inputs_spectra,inputs_mag, inputs_offset],outputs = [outputs_parallax_with_offset])\n",
    "    \n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 7514, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 7512, 4)      16          input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 3756, 4)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 15024)        0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 128)          1923200     flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 64)           8256        dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 32)           2080        dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Offset-input (InputLayer)       [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 16)           528         dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 32)           128         Offset-input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 1)            17          dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ApparentMagnitude-input (InputL [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 16)           528         dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Output-physical-parallax (Lambd (None, 1)            0           dense_61[0][0]                   \n",
      "                                                                 ApparentMagnitude-input[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 1)            17          dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Output-parallax-with-offset (La (None, 1)            0           Output-physical-parallax[0][0]   \n",
      "                                                                 dense_64[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,934,770\n",
      "Trainable params: 1,934,770\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_features = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "Global_model = ApogeeDR14GaiaDR2(n_timesteps , n_features)\n",
    "\n",
    "Global_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 19.4721 - mse: 19.4721\n",
      "Epoch 00001: val_loss improved from inf to 18.00375, saving model to /home/anell/Desktop/TesisAnell/Models_NN/model_1.h5\n",
      "24/24 [==============================] - 31s 1s/step - loss: 19.4721 - mse: 19.4721 - val_loss: 18.0037 - val_mse: 18.0037\n",
      "Epoch 2/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 18.3256 - mse: 18.3256\n",
      "Epoch 00002: val_loss improved from 18.00375 to 17.50764, saving model to /home/anell/Desktop/TesisAnell/Models_NN/model_1.h5\n",
      "24/24 [==============================] - 3s 109ms/step - loss: 18.3256 - mse: 18.3256 - val_loss: 17.5076 - val_mse: 17.5076\n",
      "Epoch 3/30\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 17.8747 - mse: 17.8747\n",
      "Epoch 00003: val_loss improved from 17.50764 to 17.39355, saving model to /home/anell/Desktop/TesisAnell/Models_NN/model_1.h5\n",
      "24/24 [==============================] - 3s 109ms/step - loss: 17.6930 - mse: 17.6930 - val_loss: 17.3935 - val_mse: 17.3935\n",
      "Epoch 4/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 17.2991 - mse: 17.2991\n",
      "Epoch 00004: val_loss did not improve from 17.39355\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 17.2991 - mse: 17.2991 - val_loss: 17.4919 - val_mse: 17.4919\n",
      "Epoch 5/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 17.0794 - mse: 17.0794\n",
      "Epoch 00005: val_loss did not improve from 17.39355\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 17.0794 - mse: 17.0794 - val_loss: 17.7277 - val_mse: 17.7277\n",
      "Epoch 6/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 16.9477 - mse: 16.9477\n",
      "Epoch 00006: val_loss did not improve from 17.39355\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 16.9477 - mse: 16.9477 - val_loss: 18.0729 - val_mse: 18.0729\n",
      "Epoch 7/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 16.7975 - mse: 16.7975\n",
      "Epoch 00007: val_loss did not improve from 17.39355\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 16.7975 - mse: 16.7975 - val_loss: 18.5206 - val_mse: 18.5206\n",
      "Epoch 8/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 16.7770 - mse: 16.7770\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 17.39355\n",
      "24/24 [==============================] - 2s 100ms/step - loss: 16.7770 - mse: 16.7770 - val_loss: 19.0699 - val_mse: 19.0699\n",
      "Epoch 9/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 16.7290 - mse: 16.7290\n",
      "Epoch 00009: val_loss did not improve from 17.39355\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 16.7290 - mse: 16.7290 - val_loss: 19.1253 - val_mse: 19.1253\n",
      "Epoch 10/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 16.6989 - mse: 16.6989\n",
      "Epoch 00010: val_loss did not improve from 17.39355\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 16.6989 - mse: 16.6989 - val_loss: 19.1807 - val_mse: 19.1807\n",
      "Epoch 11/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 16.6963 - mse: 16.6963\n",
      "Epoch 00011: val_loss did not improve from 17.39355\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 16.6963 - mse: 16.6963 - val_loss: 19.2399 - val_mse: 19.2399\n",
      "Epoch 12/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 16.6755 - mse: 16.6755\n",
      "Epoch 00012: val_loss did not improve from 17.39355\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 16.6755 - mse: 16.6755 - val_loss: 19.2952 - val_mse: 19.2952\n",
      "Epoch 13/30\n",
      "24/24 [==============================] - ETA: 0s - loss: 16.6127 - mse: 16.6127\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 17.39355\n",
      "24/24 [==============================] - 3s 105ms/step - loss: 16.6127 - mse: 16.6127 - val_loss: 19.3546 - val_mse: 19.3546\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fad34108d90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Global_model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "path_local = \"/home/anell/Desktop/TesisAnell/Models_NN\"\n",
    "\n",
    "callbacks = [EarlyStopping(patience=10, verbose=1), ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1), \n",
    "             ModelCheckpoint(f'{path_local}/model_1.h5', verbose=1, save_best_only=True)]\n",
    "\n",
    "Global_model.fit([X_train,K_mag_train,X_offset_train], Y_train, batch_size=256, shuffle='batch', \n",
    "                 epochs=30, callbacks=callbacks, validation_data=([X_val,K_mag_val,X_offset_val], Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
